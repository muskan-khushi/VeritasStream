import pika
import json
import os
import sys
import re
import numpy as np
from pymongo import MongoClient
from minio import Minio
from dotenv import load_dotenv
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from gtts import gTTS
from collections import Counter
import math

load_dotenv()

# --- Configuration ---
MONGO_URI = os.getenv("MONGO_URI", "mongodb://localhost:27017/veritas_stream")
RABBIT_URI = os.getenv("RABBIT_URI", "amqp://guest:guest@127.0.0.1:5672")
MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT", "localhost:9000")
MINIO_ACCESS = os.getenv("MINIO_ACCESS_KEY")
MINIO_SECRET = os.getenv("MINIO_SECRET_KEY")

# --- Connect Services ---
print("‚è≥ Connecting to MongoDB...")
mongo_client = MongoClient(MONGO_URI)
db = mongo_client.get_database()
reports_collection = db.reports 

print("‚è≥ Connecting to MinIO...")
minio_client = Minio(MINIO_ENDPOINT, access_key=MINIO_ACCESS, secret_key=MINIO_SECRET, secure=False)

# --- THREAT INTELLIGENCE DATABASE ---
THREAT_PATTERNS = {
    'ransomware': {
        'keywords': ['encrypt', 'locked', 'wannacry', 'ransom', 'bitcoin', 'decrypt', 
                     '.encrypted', 'shadow copy delete', 'vssadmin delete'],
        'severity': 98,
        'description': 'Critical ransomware encryption sequence detected',
        'action': 'Immediate network isolation and backup verification required'
    },
    'sql_injection': {
        'keywords': ['union select', "or 1=1", "' or '1'='1", 'drop table', 'xp_cmdshell',
                     'exec(', '--', '/*', 'information_schema'],
        'severity': 95,
        'description': 'SQL injection attack targeting database integrity',
        'action': 'Block source IP, enable prepared statements, audit database permissions'
    },
    'brute_force': {
        'keywords': ['failed password', 'authentication failure', 'invalid credentials',
                     'login failed', 'access denied', 'auth error'],
        'severity': 85,
        'description': 'Automated credential stuffing or brute force attack',
        'action': 'Enable account lockout policies and multi-factor authentication'
    },
    'privilege_escalation': {
        'keywords': ['privilege escalation', 'sudo', 'runas', 'setusertoken', 
                     'root access', 'admin rights', 'UAC bypass'],
        'severity': 92,
        'description': 'Unauthorized privilege elevation attempt detected',
        'action': 'Review user permissions and audit security policies'
    },
    'port_scanning': {
        'keywords': ['port scan', 'nmap', 'connection attempt', 'syn flood',
                     'network probe', 'host discovery'],
        'severity': 75,
        'description': 'Network reconnaissance and port scanning activity',
        'action': 'Enable IDS/IPS and monitor for follow-up attacks'
    },
    'malware': {
        'keywords': ['trojan', 'backdoor', 'rootkit', 'keylogger', 'botnet',
                     'c2 server', 'command and control', 'shellcode'],
        'severity': 94,
        'description': 'Malware infection or command-and-control communication',
        'action': 'Quarantine host and perform full forensic analysis'
    },
    'data_exfiltration': {
        'keywords': ['large transfer', 'unusual upload', 'ftp', 'sftp', 'scp',
                     'data leak', 'exfiltration', 'suspicious outbound'],
        'severity': 89,
        'description': 'Potential data exfiltration or unauthorized data transfer',
        'action': 'Block outbound connections and investigate user activity'
    }
}

# --- ADVANCED FEATURE EXTRACTION ---
def calculate_entropy(text):
    """Calculate Shannon entropy to detect encrypted/obfuscated content"""
    if not text:
        return 0.0
    
    counter = Counter(text)
    length = len(text)
    entropy = -sum((count/length) * math.log2(count/length) for count in counter.values())
    return entropy

def extract_advanced_features(lines):
    """
    Extract 15+ production-grade features per line:
    - Statistical: length, entropy, special chars
    - Linguistic: uppercase ratio, digit ratio
    - Security: SQL patterns, command injection indicators
    """
    features = []
    
    for line in lines:
        if not line.strip():
            features.append([0] * 15)
            continue
            
        length = len(line)
        
        # Basic statistical features
        special_chars = sum(1 for c in line if not c.isalnum() and not c.isspace())
        entropy = calculate_entropy(line)
        
        # Character type ratios
        uppercase_ratio = sum(1 for c in line if c.isupper()) / length if length > 0 else 0
        digit_ratio = sum(1 for c in line if c.isdigit()) / length if length > 0 else 0
        space_ratio = sum(1 for c in line if c.isspace()) / length if length > 0 else 0
        
        # Security indicators
        has_sql_keywords = int(any(kw in line.lower() for kw in ['select', 'union', 'drop', 'insert']))
        has_command_chars = int(any(c in line for c in ['|', '&', ';', '>', '<', '`']))
        has_encoding = int(any(enc in line.lower() for enc in ['base64', 'hex', 'unicode']))
        
        # Structural features
        unique_char_ratio = len(set(line)) / length if length > 0 else 0
        consecutive_spaces = max(len(s) for s in re.findall(r' +', line)) if ' ' in line else 0
        
        # Anomaly indicators
        has_non_ascii = int(any(ord(c) > 127 for c in line))
        long_words = sum(1 for word in line.split() if len(word) > 20)
        repeated_patterns = len(re.findall(r'(.{3,})\1+', line))  # Detect repetitions
        
        features.append([
            length,
            special_chars,
            entropy,
            uppercase_ratio,
            digit_ratio,
            space_ratio,
            has_sql_keywords,
            has_command_chars,
            has_encoding,
            unique_char_ratio,
            consecutive_spaces,
            has_non_ascii,
            long_words,
            repeated_patterns,
            special_chars / length if length > 0 else 0  # Special char density
        ])
    
    return np.array(features)

# --- PATTERN MATCHING ENGINE ---
def detect_threat_patterns(content):
    """
    Advanced pattern matching with severity scoring
    Returns: (threat_type, confidence, matches)
    """
    content_lower = content.lower()
    detected_threats = []
    
    for threat_type, threat_data in THREAT_PATTERNS.items():
        matches = [kw for kw in threat_data['keywords'] if kw in content_lower]
        
        if matches:
            # Calculate confidence based on number and rarity of matches
            confidence = min(100, 60 + (len(matches) * 10))
            detected_threats.append({
                'type': threat_type,
                'confidence': confidence,
                'severity': threat_data['severity'],
                'matches': matches,
                'description': threat_data['description'],
                'action': threat_data['action']
            })
    
    if detected_threats:
        # Return highest severity threat
        return max(detected_threats, key=lambda x: x['severity'])
    
    return None

# --- MACHINE LEARNING ANALYSIS ---
def ml_anomaly_detection(X, lines):
    """
    Multi-model approach:
    1. Isolation Forest for unsupervised anomaly detection
    2. Statistical thresholding for high-confidence anomalies
    """
    if len(X) < 5:
        return [], []
    
    # Normalize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Isolation Forest
    iso_model = IsolationForest(
        n_estimators=200,
        contamination=0.1,
        max_samples='auto',
        random_state=42,
        n_jobs=-1
    )
    iso_model.fit(X_scaled)
    predictions = iso_model.predict(X_scaled)
    anomaly_scores = iso_model.decision_function(X_scaled)
    
    # Identify anomalies
    anomaly_indices = [i for i, pred in enumerate(predictions) if pred == -1]
    
    # Extract suspicious lines
    suspicious_lines = []
    for idx in anomaly_indices[:10]:  # Top 10 anomalies
        if idx < len(lines):
            suspicious_lines.append({
                'line_number': idx + 1,
                'content': lines[idx][:200],
                'score': float(-anomaly_scores[idx])
            })
    
    return anomaly_indices, suspicious_lines

# --- RISK SCORING ENGINE ---
def calculate_risk_score(anomaly_count, total_lines, threat_pattern, ml_scores):
    """
    Multi-factor risk scoring:
    - ML anomaly ratio
    - Pattern matching confidence
    - Statistical deviation
    """
    # Base ML score (0-40 points)
    anomaly_ratio = anomaly_count / total_lines if total_lines > 0 else 0
    ml_score = min(40, anomaly_ratio * 400)
    
    # Pattern matching score (0-50 points)
    pattern_score = 0
    if threat_pattern:
        pattern_score = (threat_pattern['severity'] / 100) * 50
    
    # Anomaly severity score (0-10 points)
    if ml_scores:
        avg_anomaly_severity = np.mean([abs(s) for s in ml_scores])
        severity_score = min(10, avg_anomaly_severity * 2)
    else:
        severity_score = 0
    
    final_score = int(ml_score + pattern_score + severity_score)
    return min(100, final_score)

# --- VOICE ALERT GENERATION ---
def generate_voice_alert(text, case_id):
    """Generate professional voice briefing"""
    try:
        print("üó£Ô∏è Generating Voice Alert...")
        safe_filename = case_id.replace("/", "_").replace("\\", "_")
        local_filename = f"{safe_filename}_alert.mp3"
        
        tts = gTTS(text=text, lang='en', tld='co.uk', slow=False)
        tts.save(local_filename)
        
        minio_path = f"audio/{local_filename}"
        minio_client.fput_object("forensics-evidence", minio_path, local_filename)
        
        os.remove(local_filename)
        print(f"‚úÖ Audio uploaded: {minio_path}")
        return minio_path
    except Exception as e:
        print(f"‚ùå Voice Error: {e}")
        return None

# --- MAIN ANALYSIS PIPELINE ---
def analyze_log_file(bucket, object_name):
    """
    Production-grade analysis pipeline:
    1. Download and parse logs
    2. Extract advanced features
    3. Run ML models
    4. Perform pattern matching
    5. Calculate risk scores
    6. Generate reports and alerts
    """
    print(f"üß† Starting Production Analysis: {object_name}")
    
    try:
        # Download file
        response = minio_client.get_object(bucket, object_name)
        content_str = response.read().decode('utf-8', errors='ignore')
        lines = [line.strip() for line in content_str.splitlines() if line.strip()]
        response.close()
        response.release_conn()
        
        print(f"üìÑ Processing {len(lines)} log entries...")
    except Exception as e:
        print(f"‚ùå MinIO Error: {e}")
        return None

    if len(lines) < 3:
        return {
            "anomalies": 0,
            "risk_score": 0,
            "summary": "Insufficient data for analysis (minimum 3 lines required)",
            "attack_type": "Unknown",
            "recommended_action": "Upload larger log file",
            "audio_url": None,
            "plot_data": [],
            "confidence": 0
        }

    # STEP 1: Feature Extraction
    print("üî¨ Extracting features...")
    X = extract_advanced_features(lines)
    
    # STEP 2: ML Anomaly Detection
    print("ü§ñ Running ML models...")
    anomaly_indices, suspicious_lines = ml_anomaly_detection(X, lines)
    
    # STEP 3: Pattern Matching
    print("üîç Scanning for threat patterns...")
    threat_pattern = detect_threat_patterns(content_str)
    
    # STEP 4: Calculate Risk Score
    ml_scores = [X[i][-1] for i in anomaly_indices] if anomaly_indices else []
    risk_score = calculate_risk_score(
        len(anomaly_indices),
        len(lines),
        threat_pattern,
        ml_scores
    )
    
    # STEP 5: Generate Intelligence Report
    if threat_pattern:
        attack_type = threat_pattern['type'].replace('_', ' ').title()
        summary = f"{threat_pattern['description']}. ML detected {len(anomaly_indices)} anomalous patterns across {len(lines)} log entries."
        action = threat_pattern['action']
        confidence = threat_pattern['confidence']
    else:
        if len(anomaly_indices) > len(lines) * 0.1:
            attack_type = "Unknown Threat"
            summary = f"ML detected {len(anomaly_indices)} significant behavioral anomalies without matching known attack signatures. Manual investigation recommended."
            action = "Perform deep forensic analysis and threat hunting"
            confidence = 70
        else:
            attack_type = "Normal Activity"
            summary = f"Analyzed {len(lines)} log entries. All patterns within acceptable thresholds. No significant anomalies detected."
            action = "Continue routine monitoring"
            confidence = 95
    
    # STEP 6: Generate Plot Data (Real ML Scores)
    plot_data = []
    for i in range(len(lines)):
        # Calculate per-line risk based on features
        line_features = X[i]
        line_risk = (
            line_features[2] * 20 +  # Entropy
            line_features[6] * 30 +  # SQL keywords
            line_features[7] * 25 +  # Command chars
            line_features[11] * 15   # Non-ASCII
        )
        
        plot_data.append({
            "line": i + 1,
            "risk": round(min(100, max(0, line_risk)), 2),
            "is_anomaly": i in anomaly_indices
        })
    
    # STEP 7: Voice Alert
    audio_url = None
    if risk_score > 30:
        voice_text = (
            f"Veritas Security Alert. {attack_type} detected with {confidence} percent confidence. "
            f"Risk level: {risk_score}. {summary[:150]} Recommended action: {action}"
        )
        audio_url = generate_voice_alert(voice_text, object_name)
    
    print(f"‚úÖ Analysis Complete - Risk: {risk_score}%, Anomalies: {len(anomaly_indices)}")
    
    return {
        "anomalies": len(anomaly_indices),
        "risk_score": risk_score,
        "summary": summary,
        "attack_type": attack_type,
        "recommended_action": action,
        "confidence": confidence,
        "audio_url": audio_url,
        "plot_data": plot_data,
        "suspicious_lines": suspicious_lines[:5]  # Top 5 for reporting
    }

# --- RABBITMQ WORKER ---
def callback(ch, method, properties, body):
    data = json.loads(body)
    full_path = data.get('objectName')
    bucket = data.get('bucket', 'forensics-evidence')
    
    print(f"\n{'='*60}")
    print(f"üì• NEW TASK: {full_path}")
    print(f"{'='*60}")

    try:
        # Update status
        reports_collection.update_one(
            {"evidence_id": full_path},
            {"$set": {"status": "PROCESSING"}},
            upsert=False
        )

        # Run analysis
        result = analyze_log_file(bucket, full_path)

        if result:
            # Update with complete results
            update_result = reports_collection.update_one(
                {"evidence_id": full_path},
                {"$set": {
                    "status": "COMPLETED",
                    "anomalies_found": result['anomalies'],
                    "risk_score": result['risk_score'],
                    "ai_summary": result['summary'],
                    "attack_type": result['attack_type'],
                    "recommended_action": result['recommended_action'],
                    "confidence": result['confidence'],
                    "audio_url": result['audio_url'],
                    "plot_data": result['plot_data']
                }}
            )
            
            if update_result.modified_count > 0:
                print(f"‚úÖ Database updated successfully")
            else:
                print(f"‚ö†Ô∏è WARNING: No database record found for {full_path}")
        else:
            reports_collection.update_one(
                {"evidence_id": full_path},
                {"$set": {"status": "FAILED"}}
            )

    except Exception as e:
        print(f"‚ùå Worker Error: {e}")
        import traceback
        traceback.print_exc()
        
        reports_collection.update_one(
            {"evidence_id": full_path},
            {"$set": {"status": "FAILED", "error": str(e)}}
        )

    ch.basic_ack(delivery_tag=method.delivery_tag)
    print(f"{'='*60}\n")

def start_worker():
    print("\n" + "="*60)
    print("üöÄ VERITAS NEURAL ENGINE v3.0 - PRODUCTION MODE")
    print("="*60)
    print("üìä ML Models: Isolation Forest + Pattern Matching")
    print("üî¨ Features: 15-dimensional analysis per log line")
    print("üó£Ô∏è Voice Alerts: Enabled")
    print("="*60 + "\n")
    
    connection = pika.BlockingConnection(pika.URLParameters(RABBIT_URI))
    channel = connection.channel()
    channel.queue_declare(queue='forensics_tasks', durable=True)
    channel.basic_qos(prefetch_count=1)
    channel.basic_consume(queue='forensics_tasks', on_message_callback=callback)
    
    print('üê∞ Listening for evidence uploads...\n')
    channel.start_consuming()

if __name__ == '__main__':
    try:
        start_worker()
    except KeyboardInterrupt:
        print("\nüõë Shutting down gracefully...")
        sys.exit(0)